{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERVMMQusPv0H"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/STASYA00/IAAC2024_tutorials/blob/main/quickstarts/05_image2image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> - Stasja's notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJvbfCHPv0J"
      },
      "source": [
        "## Image-to-Image translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JZGb5sRPv0K"
      },
      "source": [
        "### ⚙️ Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKdKgaV-Pv0K"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "%cd pytorch-CycleGAN-and-pix2pix\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYFhgKjZPv0L"
      },
      "source": [
        "### ⛄️Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f1SYDA0Pv0L"
      },
      "source": [
        "#### ☃️ Existing datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8195WhmPv0L"
      },
      "source": [
        "There are quite a few existing paired image datasets. Some of the most famous ones:\n",
        "\n",
        "* [CMP Facade Database](https://cmp.felk.cvut.cz/~tylecr1/facade/)\n",
        "* 🤩[Cityscapes](https://www.cityscapes-dataset.com/)\n",
        "* [Satellite Imagery](https://www.kaggle.com/datasets/alincijov/pix2pix-maps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVU41GMxPv0L"
      },
      "source": [
        "To download and structure a sample dataset from [the repo](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZNSzUYxPv0M"
      },
      "outputs": [],
      "source": [
        "!bash ./datasets/download_pix2pix_dataset.sh facades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7OlF7tqPv0M"
      },
      "source": [
        "#### ☃️ Custom datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_2kV_uSPv0M"
      },
      "source": [
        "A custom dataset for training pix2pix should contain paired images, where pixels in set A would correspond to _converted_ pixels in B.\n",
        "\n",
        "At first your images should be in two folders:\n",
        "- Set A\n",
        "- Set B\n",
        "\n",
        "These images need to be stitched together and split into `train`, `validation` and `test` sets, making sure that the distribution in these sets in more or less similar.\n",
        "\n",
        "Final folder structure:\n",
        "\n",
        "    .\n",
        "    ├── custom_dataset\n",
        "    │   ├── train\n",
        "    │   │   ├── img1.jpg\n",
        "    │   │   └── img2.jpg\n",
        "    │   ├── validation\n",
        "    │   │   ├── img3.jpg\n",
        "    │   │   └── img4.jpg\n",
        "    │   └── test\n",
        "    │       ├── img5.jpg\n",
        "    │       └── img6.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye644uOoPv0M"
      },
      "source": [
        "![Sample Pix2Pix dataset image](https://github.com/STASYA00/IAAC2024_tutorials/blob/main/.assets/pix2pix_sample.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO4TeEHiPv0M"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnTdeaTiPv0M"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT5KajnnPv0M"
      },
      "source": [
        "### 🫧 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DydxO75OPv0M"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpUeofooPv0M"
      },
      "source": [
        "Provide the following arguments:\n",
        "\n",
        "* `--dataroot`  - Path to your dataset __root__ folder (where train, test, val are), e.g. `./datasets/facades`\n",
        "* `--name`      - Name of the folder where the checkpoints and intermediate results would be stored (if the name is `xxx`, the models will be stored at `checkpoints/xxx`, the images at `checkpoints/web/images/`)\n",
        "* `--model`     - Model to train with, [cycle_gan | pix2pix | test | colorization]\n",
        "* `--direction` - in which direction the images are translated, whether it is A->B or B->A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9RIlj53Pv0M"
      },
      "source": [
        "Check all the possible arguments by running `!train.py --help`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AYn6-hmPv0N"
      },
      "outputs": [],
      "source": [
        "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA --display_id -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "5pS9EcUBPyHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlMN7x78Pv0N"
      },
      "outputs": [],
      "source": [
        "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GZMpoO_Pv0N"
      },
      "source": [
        "### Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkZ1y7UVPv0N"
      },
      "source": [
        "* [Original paper](https://arxiv.org/abs/1611.07004)\n",
        "* [Original Colab](https://colab.research.google.com/github/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb#scrollTo=vrdOettJxaCc)\n",
        "* [Tensorflow training](https://www.tensorflow.org/tutorials/generative/pix2pix)\n",
        "* [Demo](https://affinelayer.com/pixsrv/)\n",
        "* [Coursera GANs Specialization course](https://www.coursera.org/specializations/generative-adversarial-networks-gans)\n",
        "* [Tensorflow pix2pix implementation](https://github.com/affinelayer/pix2pix-tensorflow)\n",
        "* [PyTorch pix2pix implementation](https://github.com/mrzhu-cool/pix2pix-pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcC5SEpLPv0N"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}